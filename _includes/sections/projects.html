<br> </br>
<h1 id="Projects"><span data-i18n="skills.my_skills">Research Projects</span></h1>

<div class="archive">
    <div class="timeline" id="timeline">
        <div class="archive-title">
            <h5 class="archive-year bio">Data Elements from Video using Impartial Algorithm Tools for Extraction</h5>
        </div>

        <ul>
            <p></p>
            <div><i>Supervised by Dr. Carol Flannagan, @ Ann Arbor, Michigan, United States</i><i><span style="float:right;">May 2020 – Present</span></i></div>
            <li>Developed and tested algorithms to detect the position of hand primitive in vehicle-monitoring videos, which would be a baseline component for next-stage cell phone usage detection algorithm.</li>
            <li>Reduced misdetection of hand position in cabin-view videos by implementing a background-removal algorithm based on Optical Flow masking.</li>
            <li>Reimplemented the User Interface for a labeling software with PyQt5, which adopted a tree structure to indicate the relationship between objects in video frames and led to better labeling experience.</li>
            <li>Cooperated with peer researchers to work on posters about work in <a href="https://shenganzhang.github.io/Cell Phone Usage Behavior Detection Based on Primitive Recognition for the IVBSS and SHRP2 Datasets-Jenil Shah, Shengan Zhang-Flannagan, Klinich, Karlow.pdf">Research</a>
                and <a href="https://shenganzhang.github.io/Improvement of Canvas, the User Interface and Data Structures of the Labelling Software-Ho Seok Song, Haomeng Zhang, Shengan Zhang, Emma Finkle-Klinich, Flannagan, Karlow.pdf">Tech</a> subteams</li>
            <li>Tested on SHRP2 dataset the generalizability of a 3D ConvNet model, which was trained and fine-tuned on IVBSS dataset.</li>
            <li>Trained a 3D ConvNet model on face-view videos to evaluate the model’s performance on the extraction of cell-phone-related behaviors.</li>
            <li>Cooperated with a peer researcher to work on a paper <a href="https://arxiv.org/abs/2011.14922">"<i>Driver Behavior Extraction from Videos in Naturalistic Driving Datasets with 3D ConvNets</i>" (in submission)</a>.</li>
        </ul>

        <div class="archive-title">
            <h5 class="archive-year bio">Data Augmentation based on Invariant Transform Experience Replay</h5>
        </div>

        <ul>
            <p></p>
            <div><i>Supervised by Dr. Paul Weng, Dr. Matthieu Zimmer, @ Shanghai, China</i><i><span style="float:right;">May 2020 – Aug. 2020</span></i></div>
            <li>Self-learned Deep Reinforcement Learning (RL) theory.</li>
            <li>Tested the original RL data augmentation method, which made symmetries of multi-task robot manipulator’s trajectories and targets, with DDPG model on tasks from OpenAI Gym.</li>
            <li>Proposed a method of randomly sampling reflection angles and choosing best angles based on the temporal difference errors of the corresponding symmetric trajectories to enhance the effectiveness of data augmentation.</li>
        </ul>

        <div class="archive-title">
            <h5 class="archive-year bio">Analyzer of Leg Movement Based on Wireless Transmission</h5>
        </div>

        <ul>
            <p></p>
            <div><i>Supervised by Dr. Guohua Shu, @ Shanghai, China</i><i><span style="float:right;">Jun. 2018 – Nov. 2019</span></i></div>
            <li>Co-developed algorithms leading to real-time leg movement visualization based on MPU-6050 acceleration sensors and STM-32 board.</li>
            <li>Preprocessed acceleration data to eliminate noise and designed algorithm to simulate the trajectory of leg with these data in MATLAB.</li>
        </ul>

    </div>
</div>